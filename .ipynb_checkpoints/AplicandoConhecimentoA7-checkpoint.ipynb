{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/Rogerio-mack/Machine-Learning-I/blob/main/ML7_ex_projeto.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "40b90843"
   },
   "source": [
    "<img src=\"http://meusite.mackenzie.br/rogerio/mackenzie_logo/UPM.2_horizontal_vermelho.jpg\"  width=300, align=\"right\">\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "# ***Conjunto de dados de previsão de doenças cardíacas***\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "rYx9D4GZA5o9"
   },
   "outputs": [],
   "source": [
    "#@title Identificação do Grupo\n",
    "\n",
    "#@markdown Integrantes do Grupo\n",
    "Aluno1 = '10424616, Valdiney Atílio Pedro' #@param {type:\"string\"} \n",
    "Aluno2 = '10424388, Mariana Simoes Rubio' #@param {type:\"string\"}\n",
    "Aluno3 = '10423533, Patrícia Corrêa França' #@param {type:\"string\"}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JlCIc2YooBW7"
   },
   "source": [
    "# **Apresentação**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A4-f8AtfKAn2"
   },
   "source": [
    "# Problema\n",
    "\n",
    "*O objetivo deste trabalho é prever a presença de doenças cardíacas em pacientes com base em um conjunto de variáveis preditoras, como idade, sexo, níveis de colesterol, pressão arterial, entre outras. A escolha deste problema é justificada pela sua relevância na área de saúde, onde a previsão precoce de doenças cardíacas pode ajudar a salvar vidas através de intervenções médicas mais rápidas e eficazes.*\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7LtXrRFr4hg3"
   },
   "source": [
    "# Referencial Teórico\n",
    "\n",
    "*Apresente aqui o referencial teórico empregado. Empregue as referências empregadas que devem aparecer no final do trabalho. Lembre-se, existem  referências técnicas do domínio da solução, mas também referências do domínio do problema (por exemplo, se estiver classificando reclamações de clientes, existem inúmeras referências sobre o problema de negócio em si).* "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7-pdJIiunIWL"
   },
   "source": [
    "# Metodologia \n",
    "\n",
    "Abordagem de Solução\n",
    "Dados Empregados: \n",
    "Utilizaremos o conjunto de dados disponível: https://github.com/valdineyatilio/AprendizadoDeMaquina-I/blob/main/cleaned_merged_heart_dataset.csv\n",
    "\n",
    "Tratamento dos Dados: Limpeza e normalização dos dados para garantir a qualidade do modelo.\n",
    "\n",
    "Variáveis Preditivas: Idade, sexo, pressão arterial, níveis de colesterol, etc.\n",
    "\n",
    "Objetivo: Desenvolver modelos de classificação para prever a presença de doenças cardíacas.\n",
    "\n",
    "Técnicas Empregadas: Avaliação e comparação de diferentes algoritmos de aprendizado supervisionado.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZGpU-v6CnTaG"
   },
   "source": [
    "# Resultados\n",
    "\n",
    "*Resuma aqui os resultados, principalmente incluindo tabelas e esquemas necessários.* "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "caAD2jBEn0KM"
   },
   "source": [
    "# **Implementação**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xGFJyOm1Kdtd"
   },
   "source": [
    "# Base de Dados \n",
    "\n",
    "*Descreva aqui os dados utilizados, discuta eventuais transformações e/ou seleções dos dados e preparações nos dados.* \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "V_X2jqpl3UWA"
   },
   "outputs": [
    {
     "ename": "ParserError",
     "evalue": "Error tokenizing data. C error: Expected 1 fields in line 42, saw 28\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mParserError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[30], line 15\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# Carregando os dados\u001b[39;00m\n\u001b[0;32m     14\u001b[0m url \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://github.com/valdineyatilio/AprendizadoDeMaquina-I/blob/main/cleaned_merged_heart_dataset.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m---> 15\u001b[0m data \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(url)\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# Visualizando as primeiras linhas do conjunto de dados\u001b[39;00m\n\u001b[0;32m     18\u001b[0m data\u001b[38;5;241m.\u001b[39mhead()\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:948\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    936\u001b[0m     dialect,\n\u001b[0;32m    937\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    944\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m    945\u001b[0m )\n\u001b[0;32m    946\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 948\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:617\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    614\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n\u001b[0;32m    616\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m parser:\n\u001b[1;32m--> 617\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\u001b[38;5;241m.\u001b[39mread(nrows)\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1748\u001b[0m, in \u001b[0;36mTextFileReader.read\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m   1741\u001b[0m nrows \u001b[38;5;241m=\u001b[39m validate_integer(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnrows\u001b[39m\u001b[38;5;124m\"\u001b[39m, nrows)\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1743\u001b[0m     \u001b[38;5;66;03m# error: \"ParserBase\" has no attribute \"read\"\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m     (\n\u001b[0;32m   1745\u001b[0m         index,\n\u001b[0;32m   1746\u001b[0m         columns,\n\u001b[0;32m   1747\u001b[0m         col_dict,\n\u001b[1;32m-> 1748\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mread(  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[0;32m   1749\u001b[0m         nrows\n\u001b[0;32m   1750\u001b[0m     )\n\u001b[0;32m   1751\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m   1752\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py:234\u001b[0m, in \u001b[0;36mCParserWrapper.read\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m    232\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    233\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlow_memory:\n\u001b[1;32m--> 234\u001b[0m         chunks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reader\u001b[38;5;241m.\u001b[39mread_low_memory(nrows)\n\u001b[0;32m    235\u001b[0m         \u001b[38;5;66;03m# destructive to chunks\u001b[39;00m\n\u001b[0;32m    236\u001b[0m         data \u001b[38;5;241m=\u001b[39m _concatenate_chunks(chunks)\n",
      "File \u001b[1;32mparsers.pyx:843\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader.read_low_memory\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mparsers.pyx:904\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mparsers.pyx:879\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mparsers.pyx:890\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._check_tokenize_status\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mparsers.pyx:2058\u001b[0m, in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mParserError\u001b[0m: Error tokenizing data. C error: Expected 1 fields in line 42, saw 28\n"
     ]
    }
   ],
   "source": [
    "# seu código\n",
    "# Importando bibliotecas\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "# Carregando os dados\n",
    "url = \"https://github.com/valdineyatilio/AprendizadoDeMaquina-I/blob/main/cleaned_merged_heart_dataset.csv\"\n",
    "data = pd.read_csv(url)\n",
    "\n",
    "# Visualizando as primeiras linhas do conjunto de dados\n",
    "data.head()\n",
    "\n",
    "\n",
    "#Análise Exploratória dos Dados (EDA)\n",
    "# Informações gerais sobre o conjunto de dados\n",
    "data.info()\n",
    "\n",
    "# Estatísticas descritivas\n",
    "data.describe()\n",
    "\n",
    "# Verificando valores nulos\n",
    "data.isnull().sum()\n",
    "\n",
    "# Visualizando a distribuição das variáveis\n",
    "plt.figure(figsize=(15, 10))\n",
    "data.hist(bins=30, figsize=(20, 15), layout=(5, 3))\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Correlação entre as variáveis\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(data.corr(), annot=True, cmap='coolwarm')\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FGwyFHwtoO5m"
   },
   "source": [
    "## **Modelo 1**\n",
    "\n",
    "*Descreva resumidamente o modelo empregado.*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hXaglI6JoaJO"
   },
   "source": [
    "### **Modelo 1:** Preparação dos Dados\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "-8gSVEHyoeLK"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[34], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# seu código\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m#Pré-processamento dos Dados\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Separando as variáveis preditoras e a variável alvo\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m X \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mdrop(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtarget\u001b[39m\u001b[38;5;124m'\u001b[39m, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m      5\u001b[0m y \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtarget\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Dividindo os dados em treino e teste\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "# seu código\n",
    "#Pré-processamento dos Dados\n",
    "# Separando as variáveis preditoras e a variável alvo\n",
    "X = data.drop('target', axis=1)\n",
    "y = data['target']\n",
    "\n",
    "# Dividindo os dados em treino e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Normalizando os dados\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VyE3YKdQotLc"
   },
   "source": [
    "### **Modelo 1:** Modelo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "a5YneTsaotLc"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[37], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# seu código\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# Treinando o modelo de Regressão Logística\u001b[39;00m\n\u001b[0;32m      3\u001b[0m log_reg \u001b[38;5;241m=\u001b[39m LogisticRegression()\n\u001b[1;32m----> 4\u001b[0m log_reg\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Fazendo previsões\u001b[39;00m\n\u001b[0;32m      7\u001b[0m y_pred_log_reg \u001b[38;5;241m=\u001b[39m log_reg\u001b[38;5;241m.\u001b[39mpredict(X_test)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "# seu código\n",
    "# Treinando o modelo de Regressão Logística\n",
    "log_reg = LogisticRegression()\n",
    "log_reg.fit(X_train, y_train)\n",
    "\n",
    "# Fazendo previsões\n",
    "y_pred_log_reg = log_reg.predict(X_test)\n",
    "\n",
    "# Avaliando o modelo\n",
    "print(\"Acurácia do modelo de Regressão Logística:\", accuracy_score(y_test, y_pred_log_reg))\n",
    "print(\"Relatório de Classificação:\\n\", classification_report(y_test, y_pred_log_reg))\n",
    "print(\"Matriz de Confusão:\\n\", confusion_matrix(y_test, y_pred_log_reg))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SRw3t2NnotVI"
   },
   "source": [
    "### **Modelo 1:** Resultados\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "kvwQvGDOotVI"
   },
   "outputs": [],
   "source": [
    "# seu código"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n6sOVE9jo_jq"
   },
   "source": [
    "## **Modelo 2**\n",
    "\n",
    "*Descreva resumidamente o modelo empregado.*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lBW3929po_jr"
   },
   "source": [
    "### **Modelo 2:** Preparação dos Dados\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "VfJUfM16o_jr"
   },
   "outputs": [],
   "source": [
    "# seu código"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z60H0esCo_jr"
   },
   "source": [
    "### **Modelo 2:** Modelo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "GzbajY4fo_jr"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[47], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# seu código\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# Treinando o modelo de Floresta Aleatória\u001b[39;00m\n\u001b[0;32m      3\u001b[0m rf_clf \u001b[38;5;241m=\u001b[39m RandomForestClassifier()\n\u001b[1;32m----> 4\u001b[0m rf_clf\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Fazendo previsões\u001b[39;00m\n\u001b[0;32m      7\u001b[0m y_pred_rf \u001b[38;5;241m=\u001b[39m rf_clf\u001b[38;5;241m.\u001b[39mpredict(X_test)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "# seu código\n",
    "# Treinando o modelo de Floresta Aleatória\n",
    "rf_clf = RandomForestClassifier()\n",
    "rf_clf.fit(X_train, y_train)\n",
    "\n",
    "# Fazendo previsões\n",
    "y_pred_rf = rf_clf.predict(X_test)\n",
    "\n",
    "# Avaliando o modelo\n",
    "print(\"Acurácia do modelo de Floresta Aleatória:\", accuracy_score(y_test, y_pred_rf))\n",
    "print(\"Relatório de Classificação:\\n\", classification_report(y_test, y_pred_rf))\n",
    "print(\"Matriz de Confusão:\\n\", confusion_matrix(y_test, y_pred_rf))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f66UTm3So_js"
   },
   "source": [
    "### **Modelo 2:** Resultados\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "PJGbWBofo_jt"
   },
   "outputs": [],
   "source": [
    "# seu código"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9kwoGZeSLRsX"
   },
   "source": [
    "# **Conclusão** \n",
    "\n",
    "*Apresente a conclusão do seu estudo comparando ainda os resultados obtidos com o referencial teórico apresentado.*\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hc0rg9YSzRz9"
   },
   "source": [
    "# **Referências** \n",
    "\n",
    "*Indique as referências empregadas, incluindo as fontes de dados.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8crUBC3IQ3U_"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "cellView": "form",
    "id": "BluFtfHuCGzm"
   },
   "outputs": [],
   "source": [
    "#@title Avaliação\n",
    "Completo = 10 #@param {type:\"slider\", min:0, max:10, step:1}\n",
    "#@markdown Projeto cumpre todos os itens pedidos. \n",
    "Relevancia = 9 #@param {type:\"slider\", min:0, max:10, step:1}\n",
    "#@markdown As seleções de dados e eventos para análise são relevantes e justificados. \n",
    "Tecnicas = 6 #@param {type:\"slider\", min:0, max:10, step:1}\n",
    "#@markdown As técnicas de empregadas são adequadas e corretamente aplicadas.\n",
    "Apresentacao = 7 #@param {type:\"slider\", min:0, max:10, step:1}\n",
    "#@markdown A apresentação dos resultados é clara e objetiva.\n",
    "Analise = 8 #@param {type:\"slider\", min:0, max:10, step:1}\n",
    "#@markdown As premissas de análise se justificam e a analise é correta. \n",
    "Conclusao = 7 #@param {type:\"slider\", min:0, max:10, step:1}\n",
    "#@markdown As conclusões são justificadas e relevantes\n",
    "Bonus = 0.5 #@param {type:\"slider\", min:0, max:1, step:0.5}\n",
    "#@markdown A critério do professor por inovações na abordagem e no uso de técnicas de Análise de Dados\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 148
    },
    "id": "2Gqw7hUZHyle",
    "outputId": "17dc9379-224b-4a07-e5c3-aa059ba434d8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nota final do trabalho 8.3\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'Aluno4' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[57], line 17\u001b[0m\n\u001b[0;32m     14\u001b[0m lista_nome \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m6\u001b[39m):\n\u001b[1;32m---> 17\u001b[0m   exec(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mif Aluno\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(i) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m !=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNone\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m:  lista = Aluno\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(i) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.split(\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m); lista_tia.append(lista[0]); lista_nome.append(lista[1].upper())\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     19\u001b[0m alunos[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtia\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m lista_tia\n\u001b[0;32m     20\u001b[0m alunos[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnome\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m lista_nome\n",
      "File \u001b[1;32m<string>:1\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Aluno4' is not defined"
     ]
    }
   ],
   "source": [
    "#@markdown ### Nota Final\n",
    "nota = Completo + Relevancia + Tecnicas + Apresentacao + Analise + Conclusao \n",
    "\n",
    "nota = nota / 6 + Bonus\n",
    "\n",
    "print(f'Nota final do trabalho {nota :.1f}')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "alunos = pd.DataFrame()\n",
    "\n",
    "lista_tia = []\n",
    "lista_nome = []\n",
    "\n",
    "for i in range(1,6):\n",
    "  exec(\"if Aluno\" + str(i) + \" !='None':  lista = Aluno\" + str(i) + \".split(','); lista_tia.append(lista[0]); lista_nome.append(lista[1].upper())\")\n",
    "\n",
    "alunos['tia'] = lista_tia\n",
    "alunos['nome'] = lista_nome\n",
    "alunos['nota'] = np.round(nota,1)\n",
    "print()\n",
    "alunos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "ML7_ex_projeto.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
